{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 22:02:25.620086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-26 22:02:25.632510: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-26 22:02:25.635976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 22:02:25.645215: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 22:02:26.375064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization as BN,\n",
    "    GlobalMaxPooling2D, Activation, Flatten, Dense\n",
    ")\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_label(xml_file, class_name=\"weed\"):\n",
    "    \"\"\"Parse a single Pascal VOC XML file to extract bounding boxes.\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get image dimensions\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    boxes = []\n",
    "    for obj in root.iter('object'):\n",
    "        name = obj.find('name').text\n",
    "        if name == class_name:\n",
    "            # Get bounding box coordinates\n",
    "            xmlbox = obj.find('bndbox')\n",
    "            xmin = int(xmlbox.find('xmin').text) / width\n",
    "            ymin = int(xmlbox.find('ymin').text) / height\n",
    "            xmax = int(xmlbox.find('xmax').text) / width\n",
    "            ymax = int(xmlbox.find('ymax').text) / height\n",
    "\n",
    "            # Store in YOLO format: (x_center, y_center, width, height)\n",
    "            x_center = (xmin + xmax) / 2\n",
    "            y_center = (ymin + ymax) / 2\n",
    "            box_width = xmax - xmin\n",
    "            box_height = ymax - ymin\n",
    "            boxes.append([x_center, y_center, box_width, box_height])\n",
    "\n",
    "    return np.array(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_folder, xml_folder, input_size=(416, 416)):\n",
    "    X = []  # Images\n",
    "    y = []  # Labels (bounding boxes)\n",
    "\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            xml_path = os.path.join(xml_folder, xml_file)\n",
    "\n",
    "            # Parse the XML for bounding boxes\n",
    "            boxes = parse_xml_label(xml_path)\n",
    "\n",
    "            # Load the corresponding image\n",
    "            img_file = xml_file.replace('.xml', '.jpg')\n",
    "            img_path = os.path.join(image_folder, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not load image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # Resize and normalize the image\n",
    "            img = cv2.resize(img, input_size)\n",
    "            img = img / 255.0\n",
    "\n",
    "            X.append(img)\n",
    "            y.append(boxes)\n",
    "\n",
    "    return np.array(X), np.array(y, dtype=object)\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "X_train, y_train = load_data('images', 'processed_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded labels shape: (278, 15, 5)\n"
     ]
    }
   ],
   "source": [
    "def add_class_score_to_labels(labels, class_score=1.0):\n",
    "    \"\"\"Add a class score to each bounding box.\"\"\"\n",
    "    new_labels = []\n",
    "    for boxes in labels:\n",
    "        # Add the class score (e.g., 1.0) to each box\n",
    "        boxes_with_score = np.hstack([boxes, np.full((boxes.shape[0], 1), class_score)])\n",
    "        new_labels.append(boxes_with_score)\n",
    "    return new_labels\n",
    "\n",
    "# Add class scores to the labels\n",
    "y_train_with_scores = add_class_score_to_labels(y_train)\n",
    "\n",
    "# Pad the labels so all images have exactly 15 boxes\n",
    "num_boxes = 15  # Maximum number of boxes per image\n",
    "y_train_padded = pad_sequences(y_train_with_scores, maxlen=num_boxes, padding='post', dtype='float32')\n",
    "\n",
    "print(\"Padded labels shape:\", y_train_padded.shape)  # Should be (num_images, 15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730005394.397840 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.413879 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.414101 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.415633 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.415900 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.416120 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.565055 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730005394.565338 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-26 22:03:14.565354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730005394.565543 2347707 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-26 22:03:14.565571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730005398.230558 2348080 service.cc:146] XLA service 0x7f78280996c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730005398.230597 2348080 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-26 22:03:18.284011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-26 22:03:18.543954: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-26 22:03:19.974338: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2313', 480 bytes spill stores, 480 bytes spill loads\n",
      "\n",
      "2024-10-26 22:03:19.996473: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2313', 504 bytes spill stores, 504 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/28\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2361 - loss: 2.5292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730005406.780386 2348080 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2442 - loss: 1.5377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 22:03:29.003984: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2313', 512 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2024-10-26 22:03:29.023482: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2313', 480 bytes spill stores, 480 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 339ms/step - accuracy: 0.2447 - loss: 1.5078 - val_accuracy: 0.1488 - val_loss: 0.2662\n",
      "Epoch 2/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2907 - loss: 0.5276 - val_accuracy: 0.1167 - val_loss: 0.3421\n",
      "Epoch 3/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2963 - loss: 0.3172 - val_accuracy: 0.1310 - val_loss: 0.3316\n",
      "Epoch 4/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.3509 - loss: 0.2307 - val_accuracy: 0.2107 - val_loss: 0.2638\n",
      "Epoch 5/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.3625 - loss: 0.1781 - val_accuracy: 0.2643 - val_loss: 0.2327\n",
      "Epoch 6/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3771 - loss: 0.1432 - val_accuracy: 0.3381 - val_loss: 0.2007\n",
      "Epoch 7/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4094 - loss: 0.1221 - val_accuracy: 0.3774 - val_loss: 0.1695\n",
      "Epoch 8/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4047 - loss: 0.1036 - val_accuracy: 0.3869 - val_loss: 0.1556\n",
      "Epoch 9/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4505 - loss: 0.0885 - val_accuracy: 0.3988 - val_loss: 0.1427\n",
      "Epoch 10/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4338 - loss: 0.0764 - val_accuracy: 0.3976 - val_loss: 0.1254\n",
      "Epoch 11/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4653 - loss: 0.0674 - val_accuracy: 0.4036 - val_loss: 0.1175\n",
      "Epoch 12/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4484 - loss: 0.0588 - val_accuracy: 0.3976 - val_loss: 0.1206\n",
      "Epoch 13/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4760 - loss: 0.0513 - val_accuracy: 0.4310 - val_loss: 0.1044\n",
      "Epoch 14/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4800 - loss: 0.0436 - val_accuracy: 0.4286 - val_loss: 0.1033\n",
      "Epoch 15/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4741 - loss: 0.0386 - val_accuracy: 0.4214 - val_loss: 0.0991\n",
      "Epoch 16/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5021 - loss: 0.0349 - val_accuracy: 0.4095 - val_loss: 0.0933\n",
      "Epoch 17/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5205 - loss: 0.0291 - val_accuracy: 0.3667 - val_loss: 0.0930\n",
      "Epoch 18/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4943 - loss: 0.0289 - val_accuracy: 0.3524 - val_loss: 0.0914\n",
      "Epoch 19/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 0.0265 - val_accuracy: 0.3655 - val_loss: 0.0950\n",
      "Epoch 20/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5360 - loss: 0.0203 - val_accuracy: 0.3274 - val_loss: 0.0980\n",
      "Epoch 21/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5092 - loss: 0.0196 - val_accuracy: 0.3333 - val_loss: 0.1076\n",
      "Epoch 22/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5054 - loss: 0.0172 - val_accuracy: 0.3190 - val_loss: 0.1180\n",
      "Epoch 23/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5080 - loss: 0.0159 - val_accuracy: 0.3071 - val_loss: 0.1280\n",
      "Epoch 24/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5351 - loss: 0.0141 - val_accuracy: 0.3048 - val_loss: 0.1404\n",
      "Epoch 25/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5131 - loss: 0.0142 - val_accuracy: 0.2964 - val_loss: 0.1503\n",
      "Epoch 26/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5041 - loss: 0.0129 - val_accuracy: 0.2952 - val_loss: 0.1618\n",
      "Epoch 27/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5122 - loss: 0.0117 - val_accuracy: 0.2964 - val_loss: 0.1714\n",
      "Epoch 28/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5299 - loss: 0.0100 - val_accuracy: 0.2881 - val_loss: 0.1809\n",
      "Epoch 29/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5248 - loss: 0.0090 - val_accuracy: 0.2988 - val_loss: 0.1882\n",
      "Epoch 30/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5013 - loss: 0.0109 - val_accuracy: 0.2917 - val_loss: 0.1953\n",
      "Epoch 31/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5313 - loss: 0.0076 - val_accuracy: 0.2869 - val_loss: 0.2015\n",
      "Epoch 32/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5448 - loss: 0.0068 - val_accuracy: 0.2976 - val_loss: 0.2037\n",
      "Epoch 33/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5172 - loss: 0.0095 - val_accuracy: 0.2702 - val_loss: 0.2028\n",
      "Epoch 34/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4985 - loss: 0.0071 - val_accuracy: 0.2929 - val_loss: 0.2093\n",
      "Epoch 35/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5460 - loss: 0.0074 - val_accuracy: 0.2893 - val_loss: 0.2097\n",
      "Epoch 36/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5362 - loss: 0.0061 - val_accuracy: 0.2798 - val_loss: 0.2086\n",
      "Epoch 37/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5308 - loss: 0.0069 - val_accuracy: 0.2833 - val_loss: 0.2131\n",
      "Epoch 38/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5075 - loss: 0.0072 - val_accuracy: 0.2905 - val_loss: 0.2109\n",
      "Epoch 39/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5373 - loss: 0.0058 - val_accuracy: 0.2857 - val_loss: 0.2144\n",
      "Epoch 40/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5503 - loss: 0.0074 - val_accuracy: 0.2810 - val_loss: 0.2110\n",
      "Epoch 41/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5316 - loss: 0.0054 - val_accuracy: 0.2810 - val_loss: 0.2121\n",
      "Epoch 42/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5319 - loss: 0.0055 - val_accuracy: 0.2845 - val_loss: 0.2123\n",
      "Epoch 43/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5049 - loss: 0.0064 - val_accuracy: 0.2774 - val_loss: 0.2109\n",
      "Epoch 44/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5206 - loss: 0.0059 - val_accuracy: 0.2881 - val_loss: 0.2139\n",
      "Epoch 45/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5105 - loss: 0.0048 - val_accuracy: 0.2810 - val_loss: 0.2105\n",
      "Epoch 46/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5159 - loss: 0.0056 - val_accuracy: 0.2845 - val_loss: 0.2127\n",
      "Epoch 47/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5189 - loss: 0.0051 - val_accuracy: 0.2857 - val_loss: 0.2091\n",
      "Epoch 48/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5145 - loss: 0.0076 - val_accuracy: 0.2905 - val_loss: 0.2098\n",
      "Epoch 49/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5414 - loss: 0.0059 - val_accuracy: 0.2857 - val_loss: 0.2071\n",
      "Epoch 50/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5438 - loss: 0.0074 - val_accuracy: 0.2702 - val_loss: 0.2088\n",
      "Epoch 51/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5121 - loss: 0.0042 - val_accuracy: 0.2738 - val_loss: 0.2094\n",
      "Epoch 52/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5093 - loss: 0.0059 - val_accuracy: 0.2869 - val_loss: 0.2095\n",
      "Epoch 53/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5334 - loss: 0.0061 - val_accuracy: 0.2869 - val_loss: 0.2041\n",
      "Epoch 54/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5491 - loss: 0.0061 - val_accuracy: 0.2952 - val_loss: 0.2066\n",
      "Epoch 55/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5280 - loss: 0.0047 - val_accuracy: 0.2750 - val_loss: 0.2064\n",
      "Epoch 56/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5068 - loss: 0.0068 - val_accuracy: 0.2857 - val_loss: 0.2072\n",
      "Epoch 57/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5188 - loss: 0.0059 - val_accuracy: 0.2881 - val_loss: 0.2026\n",
      "Epoch 58/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5113 - loss: 0.0045 - val_accuracy: 0.2833 - val_loss: 0.2032\n",
      "Epoch 59/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5220 - loss: 0.0051 - val_accuracy: 0.2940 - val_loss: 0.2084\n",
      "Epoch 60/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5122 - loss: 0.0055 - val_accuracy: 0.2869 - val_loss: 0.2047\n",
      "Epoch 61/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5769 - loss: 0.0047 - val_accuracy: 0.2821 - val_loss: 0.2002\n",
      "Epoch 62/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5624 - loss: 0.0053 - val_accuracy: 0.2857 - val_loss: 0.2015\n",
      "Epoch 63/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5559 - loss: 0.0052 - val_accuracy: 0.2845 - val_loss: 0.2006\n",
      "Epoch 64/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5232 - loss: 0.0043 - val_accuracy: 0.2940 - val_loss: 0.1992\n",
      "Epoch 65/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5309 - loss: 0.0036 - val_accuracy: 0.2833 - val_loss: 0.2000\n",
      "Epoch 66/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5306 - loss: 0.0043 - val_accuracy: 0.2881 - val_loss: 0.2003\n",
      "Epoch 67/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5314 - loss: 0.0048 - val_accuracy: 0.2845 - val_loss: 0.1990\n",
      "Epoch 68/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5231 - loss: 0.0049 - val_accuracy: 0.2845 - val_loss: 0.1984\n",
      "Epoch 69/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5213 - loss: 0.0055 - val_accuracy: 0.2940 - val_loss: 0.1972\n",
      "Epoch 70/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5348 - loss: 0.0045 - val_accuracy: 0.2857 - val_loss: 0.1969\n",
      "Epoch 71/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5253 - loss: 0.0046 - val_accuracy: 0.2893 - val_loss: 0.1977\n",
      "Epoch 72/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5257 - loss: 0.0043 - val_accuracy: 0.2905 - val_loss: 0.1964\n",
      "Epoch 73/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5097 - loss: 0.0047 - val_accuracy: 0.2964 - val_loss: 0.1956\n",
      "Epoch 74/10000\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5252 - loss: 0.0049 - val_accuracy: 0.3012 - val_loss: 0.1999\n",
      "Epoch 75/10000\n",
      "\u001b[1m25/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5383 - loss: 0.0043"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape=(416, 416, 3), num_boxes=15, lr=1e-4):\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    # Preprocessing: Normalize input\n",
    "    x = Lambda(lambda x: K.cast_to_floatx(x))(input_img)\n",
    "    x = Lambda(lambda x: x / 255.0)(x)\n",
    "\n",
    "    # Convolutional Layers\n",
    "    for filters in [16, 32, 32, 16]:\n",
    "        x = BN()(x)\n",
    "        x = Conv2D(filters, 3, padding='valid', activation='selu', kernel_initializer='lecun_normal')(x)\n",
    "        x = Conv2D(filters, 3, padding='valid', activation='selu', kernel_initializer='lecun_normal')(x)\n",
    "        x = MaxPooling2D(2)(x)\n",
    "\n",
    "    # Flatten the output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layer to predict bounding boxes (x, y, width, height) and a class score for each box\n",
    "    output = Dense(num_boxes * 5)(x)  # 5 values per box: (x, y, width, height, class)\n",
    "\n",
    "    # Reshape the output to match (batch_size, num_boxes, 5)\n",
    "    output = tf.keras.layers.Reshape((num_boxes, 5))(output)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=input_img, outputs=output)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = build_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_padded, epochs=10000, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weed_detector_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
